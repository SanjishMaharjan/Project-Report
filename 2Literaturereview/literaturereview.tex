\section{LITERATURE REVIEW}
Since 2017, the Transformer has been very renowned as a new type of neural architecture which encodes the given input data into a powerful feature, with the help of attention mechanism.  With the research article published in 2017, named "Attention Is All You Need" [6], by taking it as a framework, numerious researches has been done recently upon the visions task as well [3]. This is where the Visual Transformer comes in. 
\\\\
While the Transformer Architecture has been a new standard for Natural Language Processing tasks, its application to computer vision remains limited. From many recent studies and researches done, the common points mentioned was that in vision, either the attention is applied in conjuction with convolutional networks, or used to replace certain components of convolutional network while keeping their overall structure in place [4].
\\\\
The Transformer-liked architecture has been employed in the computer vision field in present context in three fundamental computer vision tasks, namely classification, detection and segmentation [2]. Our work lies within one of these fundamental tasks i.e the detection of artificially generated images of a human face.
\\\\
 The Visual Transformer has been gaining many contributions in recent years such that its capabilites has increased beyond the old traditional models. As a matter of fact, the Visual Transformer model has clear advantages over traditional models such as CNNs and RNNs in specific situations. It can process whole images in sections, which helps it understand the bigger picture. Also, it is good with working on different image sizes and tasks. 
 Training these models on big datasets first and then adjusting it for specific tasks makes it really flexible compared to the traditional model [5]. 
 One of its key characteristics, self-attention, not only helps us understand how the model works but also reminds us to pick the right model based on the job, data, and what we have.
\\\\
The deepfakes are created using deep learning techniques like Generative Adversarial Networks (GANs). These techniques involve two main components: a generator and a discriminator. The generator produces fake content, such as faces or scenes, while the discriminator tries to distinguish between real and fake content. Through an iterative process, the generator improves its ability to create increasingly realistic output, aiming to deceive the discriminator. 
\\\\From recent researches done Vision Transformer (ViT) is deemed more suitable than Generative Adversarial Networks (GANs) for deepfake detection because Vision Transformer is specifically designed for image analysis tasks like classification. GANs are like artists that make fake pictures, but they're not as good at spotting fakes. Also, the tricks that make GANs create fakes can also fool themselves when looking for fakes. Vision transformer way of looking at pictures makes it a good choice for catching fake ones, because it's good at seeing small things that don't match up.
\\\\
In summary, with all these distinct attributes and merits the Vision Transformer imposes itself significantly compared to others at present time, which has led us to select it as the major model for our project development.

